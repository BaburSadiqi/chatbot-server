# ğŸ¤– AI Integration with FastAPI

This project is a backend service built using **FastAPI** to integrate AI-powered features. It includes CORS support for frontend communication and uses modular route-based architecture for maintainability.

---

## ğŸš€ Features

- âš¡ FastAPI backend for AI services  
- ğŸ”„ CORS enabled for frontend/backend communication  
- ğŸ”Œ Modular route handling (e.g., `send_msg`)  
- ğŸŒ Port configuration via environment variables  
- ğŸš€ Ready for local development and deployment  

---

## ğŸ“ Project Structure
- ai-integration/
- main.py .. Entry point of the FastAPI app
- route/
- â”‚ â””â”€â”€ send_msg.py # Handles AI-related requests
- â”œâ”€â”€ requirements.txt # Python dependencies
- â””â”€â”€ README.md # Project documentation

---

## ğŸ§ª Getting Started

### 1. Clone the Repository


git clone https://github.com/BaburSadiqi/Fast-AI-Chat.git
cd Fast-AI-Chat

### 2. Create and Activate a Virtual Environment (Optional)
- python -m venv venv
- source venv/bin/activate  # On Windows: venv\Scripts\activate

### 3. Install Dependencies
- pip install fastapi uvicorn


---

# ğŸš€ Run the Application
- uvicorn main:app --reload
- App will be running at: http://127.0.0.1:8000

---

# ğŸ”Œ API Endpoint
| Method | Endpoint    | Description              |
| ------ | ----------- | ------------------------ |
| POST   | `/send-msg` | Handles AI chat messages |

(Assumes your send_msg.py defines the /send-msg route)

# âš™ï¸ Environment Variables
| Variable | Description            | Default |
| -------- | ---------------------- | ------- |
| `PORT`   | Port to run the server | `8000`  |

## To run with a specific port:
- PORT=5000 uvicorn main:app
---

## ğŸ“¦ Deployment
- uvicorn main:app --host 0.0.0.0 --port ${PORT}

---
# ğŸ‘¤ Author
Babur Sadiqi
